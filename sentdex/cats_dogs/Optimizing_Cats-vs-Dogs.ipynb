{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obvious things to tweak\n",
    "\n",
    "\n",
    "Number of layers\n",
    "Nodes per layer\n",
    "Dense layer at the end or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3-conv-32-nodes0-dense-1540613255\n",
      "3-conv-64-nodes0-dense-1540613255\n",
      "3-conv-128-nodes0-dense-1540613255\n",
      "3-conv-32-nodes1-dense-1540613255\n",
      "3-conv-64-nodes1-dense-1540613255\n",
      "3-conv-128-nodes1-dense-1540613255\n",
      "3-conv-32-nodes2-dense-1540613255\n",
      "3-conv-64-nodes2-dense-1540613255\n",
      "3-conv-128-nodes2-dense-1540613255\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "dense_layers = [0, 1, 2]\n",
    "layer_sizes = [32, 64, 128]\n",
    "conv_layers = [3]\n",
    "\n",
    "for dense_layer in dense_layers:\n",
    "    for layer_size in layer_sizes:\n",
    "        for conv_layer in conv_layers:\n",
    "            NAME = \"{}-conv-{}-nodes{}-dense-{}\".format(conv_layer, layer_size, dense_layer, int(time.time()))\n",
    "            print(NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 22451 samples, validate on 2495 samples\n",
      "Epoch 1/10\n",
      "22451/22451 [==============================] - 17s 759us/step - loss: 0.6488 - acc: 0.6194 - val_loss: 0.6195 - val_acc: 0.6425\n",
      "Epoch 2/10\n",
      "22451/22451 [==============================] - 17s 745us/step - loss: 0.5812 - acc: 0.7025 - val_loss: 0.5884 - val_acc: 0.6910\n",
      "Epoch 3/10\n",
      "22451/22451 [==============================] - 17s 751us/step - loss: 0.5173 - acc: 0.7517 - val_loss: 0.4794 - val_acc: 0.7792\n",
      "Epoch 4/10\n",
      "22451/22451 [==============================] - 17s 751us/step - loss: 0.4756 - acc: 0.7782 - val_loss: 0.4830 - val_acc: 0.7671\n",
      "Epoch 5/10\n",
      "22451/22451 [==============================] - 17s 759us/step - loss: 0.4517 - acc: 0.7936 - val_loss: 0.4388 - val_acc: 0.7980\n",
      "Epoch 6/10\n",
      "22451/22451 [==============================] - 17s 749us/step - loss: 0.4280 - acc: 0.8061 - val_loss: 0.4574 - val_acc: 0.7820\n",
      "Epoch 7/10\n",
      "22451/22451 [==============================] - 17s 752us/step - loss: 0.4084 - acc: 0.8127 - val_loss: 0.4266 - val_acc: 0.7996\n",
      "Epoch 8/10\n",
      "22451/22451 [==============================] - 17s 752us/step - loss: 0.3937 - acc: 0.8229 - val_loss: 0.4393 - val_acc: 0.7948\n",
      "Epoch 9/10\n",
      "22451/22451 [==============================] - 17s 754us/step - loss: 0.3757 - acc: 0.8310 - val_loss: 0.4046 - val_acc: 0.8184\n",
      "Epoch 10/10\n",
      "22451/22451 [==============================] - 17s 754us/step - loss: 0.3618 - acc: 0.8401 - val_loss: 0.4044 - val_acc: 0.8164\n",
      "Train on 22451 samples, validate on 2495 samples\n",
      "Epoch 1/10\n",
      "22451/22451 [==============================] - 27s 1ms/step - loss: 0.6461 - acc: 0.6217 - val_loss: 0.5948 - val_acc: 0.6922\n",
      "Epoch 2/10\n",
      "22451/22451 [==============================] - 27s 1ms/step - loss: 0.5756 - acc: 0.7088 - val_loss: 0.5417 - val_acc: 0.7259\n",
      "Epoch 3/10\n",
      "22451/22451 [==============================] - 27s 1ms/step - loss: 0.5249 - acc: 0.7439 - val_loss: 0.5035 - val_acc: 0.7563\n",
      "Epoch 4/10\n",
      "22451/22451 [==============================] - 27s 1ms/step - loss: 0.4857 - acc: 0.7708 - val_loss: 0.4751 - val_acc: 0.7715\n",
      "Epoch 5/10\n",
      "22451/22451 [==============================] - 27s 1ms/step - loss: 0.4572 - acc: 0.7911 - val_loss: 0.4604 - val_acc: 0.7812\n",
      "Epoch 6/10\n",
      "22451/22451 [==============================] - 27s 1ms/step - loss: 0.4328 - acc: 0.8014 - val_loss: 0.4652 - val_acc: 0.7868\n",
      "Epoch 7/10\n",
      "22451/22451 [==============================] - 27s 1ms/step - loss: 0.4108 - acc: 0.8119 - val_loss: 0.4412 - val_acc: 0.7972\n",
      "Epoch 8/10\n",
      "22451/22451 [==============================] - 27s 1ms/step - loss: 0.3863 - acc: 0.8266 - val_loss: 0.4581 - val_acc: 0.7852\n",
      "Epoch 9/10\n",
      "22451/22451 [==============================] - 27s 1ms/step - loss: 0.3725 - acc: 0.8335 - val_loss: 0.4431 - val_acc: 0.7968\n",
      "Epoch 10/10\n",
      "22451/22451 [==============================] - 27s 1ms/step - loss: 0.3522 - acc: 0.8437 - val_loss: 0.4400 - val_acc: 0.7992\n",
      "Train on 22451 samples, validate on 2495 samples\n",
      "Epoch 1/10\n",
      "22451/22451 [==============================] - 51s 2ms/step - loss: 0.6717 - acc: 0.5731 - val_loss: 0.6164 - val_acc: 0.6581\n",
      "Epoch 2/10\n",
      "22451/22451 [==============================] - 51s 2ms/step - loss: 0.6072 - acc: 0.6767 - val_loss: 0.5838 - val_acc: 0.6842\n",
      "Epoch 3/10\n",
      "22451/22451 [==============================] - 51s 2ms/step - loss: 0.5618 - acc: 0.7129 - val_loss: 0.5330 - val_acc: 0.7395\n",
      "Epoch 4/10\n",
      "22451/22451 [==============================] - 51s 2ms/step - loss: 0.5335 - acc: 0.7362 - val_loss: 0.5383 - val_acc: 0.7311\n",
      "Epoch 5/10\n",
      "22451/22451 [==============================] - 51s 2ms/step - loss: 0.5130 - acc: 0.7502 - val_loss: 0.5109 - val_acc: 0.7487\n",
      "Epoch 6/10\n",
      "22451/22451 [==============================] - 51s 2ms/step - loss: 0.4964 - acc: 0.7631 - val_loss: 0.5303 - val_acc: 0.7291\n",
      "Epoch 7/10\n",
      "22451/22451 [==============================] - 51s 2ms/step - loss: 0.4770 - acc: 0.7776 - val_loss: 0.4847 - val_acc: 0.7675\n",
      "Epoch 8/10\n",
      "22451/22451 [==============================] - 51s 2ms/step - loss: 0.4620 - acc: 0.7862 - val_loss: 0.4787 - val_acc: 0.7764\n",
      "Epoch 9/10\n",
      "22451/22451 [==============================] - 51s 2ms/step - loss: 0.4451 - acc: 0.7931 - val_loss: 0.5071 - val_acc: 0.7555\n",
      "Epoch 10/10\n",
      "22451/22451 [==============================] - 51s 2ms/step - loss: 0.4371 - acc: 0.7988 - val_loss: 0.5279 - val_acc: 0.7403\n",
      "Train on 22451 samples, validate on 2495 samples\n",
      "Epoch 1/10\n",
      "22451/22451 [==============================] - 17s 775us/step - loss: 0.6932 - acc: 0.4986 - val_loss: 0.6932 - val_acc: 0.4866\n",
      "Epoch 2/10\n",
      "22451/22451 [==============================] - 17s 760us/step - loss: 0.6932 - acc: 0.4972 - val_loss: 0.6933 - val_acc: 0.4866\n",
      "Epoch 3/10\n",
      "22451/22451 [==============================] - 17s 765us/step - loss: 0.6932 - acc: 0.4974 - val_loss: 0.6933 - val_acc: 0.4866\n",
      "Epoch 4/10\n",
      "22451/22451 [==============================] - 17s 768us/step - loss: 0.6932 - acc: 0.4971 - val_loss: 0.6932 - val_acc: 0.4866\n",
      "Epoch 5/10\n",
      "22451/22451 [==============================] - 17s 778us/step - loss: 0.6932 - acc: 0.4996 - val_loss: 0.6933 - val_acc: 0.4866\n",
      "Epoch 6/10\n",
      "22451/22451 [==============================] - 17s 773us/step - loss: 0.6931 - acc: 0.5019 - val_loss: 0.6935 - val_acc: 0.4866\n",
      "Epoch 7/10\n",
      "22451/22451 [==============================] - 17s 769us/step - loss: 0.6932 - acc: 0.5004 - val_loss: 0.6932 - val_acc: 0.4866\n",
      "Epoch 8/10\n",
      "22451/22451 [==============================] - 17s 773us/step - loss: 0.6932 - acc: 0.4965 - val_loss: 0.6933 - val_acc: 0.4866\n",
      "Epoch 9/10\n",
      "22451/22451 [==============================] - 17s 771us/step - loss: 0.6932 - acc: 0.4990 - val_loss: 0.6932 - val_acc: 0.4866\n",
      "Epoch 10/10\n",
      "22451/22451 [==============================] - 17s 778us/step - loss: 0.6932 - acc: 0.4973 - val_loss: 0.6932 - val_acc: 0.4866\n",
      "Train on 22451 samples, validate on 2495 samples\n",
      "Epoch 1/10\n",
      "22451/22451 [==============================] - 28s 1ms/step - loss: 0.6402 - acc: 0.6335 - val_loss: 0.5985 - val_acc: 0.7022\n",
      "Epoch 2/10\n",
      "22451/22451 [==============================] - 28s 1ms/step - loss: 0.5597 - acc: 0.7191 - val_loss: 0.5167 - val_acc: 0.7511\n",
      "Epoch 3/10\n",
      "22451/22451 [==============================] - 28s 1ms/step - loss: 0.4974 - acc: 0.7616 - val_loss: 0.5101 - val_acc: 0.7511\n",
      "Epoch 4/10\n",
      "22451/22451 [==============================] - 28s 1ms/step - loss: 0.4462 - acc: 0.7919 - val_loss: 0.4682 - val_acc: 0.7784\n",
      "Epoch 5/10\n",
      "22451/22451 [==============================] - 28s 1ms/step - loss: 0.3974 - acc: 0.8188 - val_loss: 0.4596 - val_acc: 0.7768\n",
      "Epoch 6/10\n",
      "22451/22451 [==============================] - 28s 1ms/step - loss: 0.3432 - acc: 0.8487 - val_loss: 0.4504 - val_acc: 0.7836\n",
      "Epoch 7/10\n",
      "22451/22451 [==============================] - 28s 1ms/step - loss: 0.2888 - acc: 0.8769 - val_loss: 0.4896 - val_acc: 0.8024\n",
      "Epoch 8/10\n",
      "22451/22451 [==============================] - 28s 1ms/step - loss: 0.2265 - acc: 0.9081 - val_loss: 0.5623 - val_acc: 0.7884\n",
      "Epoch 9/10\n",
      "22451/22451 [==============================] - 28s 1ms/step - loss: 0.1649 - acc: 0.9345 - val_loss: 0.6749 - val_acc: 0.7824\n",
      "Epoch 10/10\n",
      "22451/22451 [==============================] - 28s 1ms/step - loss: 0.1155 - acc: 0.9547 - val_loss: 0.7532 - val_acc: 0.7872\n",
      "Train on 22451 samples, validate on 2495 samples\n",
      "Epoch 1/10\n",
      "22451/22451 [==============================] - 54s 2ms/step - loss: 0.6787 - acc: 0.5570 - val_loss: 0.6158 - val_acc: 0.6593\n",
      "Epoch 2/10\n",
      "22451/22451 [==============================] - 54s 2ms/step - loss: 0.5893 - acc: 0.6855 - val_loss: 0.5401 - val_acc: 0.7251\n",
      "Epoch 3/10\n",
      "22451/22451 [==============================] - 54s 2ms/step - loss: 0.5275 - acc: 0.7366 - val_loss: 0.5205 - val_acc: 0.7483\n",
      "Epoch 4/10\n",
      "22451/22451 [==============================] - 54s 2ms/step - loss: 0.4790 - acc: 0.7733 - val_loss: 0.4993 - val_acc: 0.7583\n",
      "Epoch 5/10\n",
      "22451/22451 [==============================] - 53s 2ms/step - loss: 0.4176 - acc: 0.8066 - val_loss: 0.5284 - val_acc: 0.7511\n",
      "Epoch 6/10\n",
      "22451/22451 [==============================] - 54s 2ms/step - loss: 0.3317 - acc: 0.8555 - val_loss: 0.5884 - val_acc: 0.7415\n",
      "Epoch 7/10\n",
      "22451/22451 [==============================] - 54s 2ms/step - loss: 0.2325 - acc: 0.9066 - val_loss: 0.7003 - val_acc: 0.7479\n",
      "Epoch 8/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22451/22451 [==============================] - 54s 2ms/step - loss: 0.1349 - acc: 0.9480 - val_loss: 0.9484 - val_acc: 0.7315\n",
      "Epoch 9/10\n",
      "22451/22451 [==============================] - 54s 2ms/step - loss: 0.0763 - acc: 0.9723 - val_loss: 1.1931 - val_acc: 0.7230\n",
      "Epoch 10/10\n",
      "22451/22451 [==============================] - 54s 2ms/step - loss: 0.0421 - acc: 0.9860 - val_loss: 1.3845 - val_acc: 0.7311\n",
      "Train on 22451 samples, validate on 2495 samples\n",
      "Epoch 1/10\n",
      "22451/22451 [==============================] - 18s 794us/step - loss: 0.6932 - acc: 0.5003 - val_loss: 0.6931 - val_acc: 0.5134\n",
      "Epoch 2/10\n",
      "22451/22451 [==============================] - 17s 774us/step - loss: 0.6932 - acc: 0.4972 - val_loss: 0.6931 - val_acc: 0.5138\n",
      "Epoch 3/10\n",
      "22451/22451 [==============================] - 17s 768us/step - loss: 0.6932 - acc: 0.4987 - val_loss: 0.6932 - val_acc: 0.4866\n",
      "Epoch 4/10\n",
      "22451/22451 [==============================] - 17s 772us/step - loss: 0.6933 - acc: 0.4950 - val_loss: 0.6933 - val_acc: 0.4866\n",
      "Epoch 5/10\n",
      "22451/22451 [==============================] - 17s 771us/step - loss: 0.6932 - acc: 0.5000 - val_loss: 0.6932 - val_acc: 0.4866\n",
      "Epoch 6/10\n",
      "22451/22451 [==============================] - 17s 771us/step - loss: 0.6932 - acc: 0.5018 - val_loss: 0.6933 - val_acc: 0.4866\n",
      "Epoch 7/10\n",
      "22451/22451 [==============================] - 17s 771us/step - loss: 0.6932 - acc: 0.5043 - val_loss: 0.6930 - val_acc: 0.5134\n",
      "Epoch 8/10\n",
      "22451/22451 [==============================] - 17s 767us/step - loss: 0.6932 - acc: 0.5000 - val_loss: 0.6933 - val_acc: 0.4866\n",
      "Epoch 9/10\n",
      "22451/22451 [==============================] - 17s 777us/step - loss: 0.6932 - acc: 0.5009 - val_loss: 0.6932 - val_acc: 0.4866\n",
      "Epoch 10/10\n",
      "22451/22451 [==============================] - 17s 778us/step - loss: 0.6932 - acc: 0.5023 - val_loss: 0.6933 - val_acc: 0.4866\n",
      "Train on 22451 samples, validate on 2495 samples\n",
      "Epoch 1/10\n",
      "22451/22451 [==============================] - 28s 1ms/step - loss: 0.6742 - acc: 0.5601 - val_loss: 0.6188 - val_acc: 0.6581\n",
      "Epoch 2/10\n",
      "22451/22451 [==============================] - 28s 1ms/step - loss: 0.6016 - acc: 0.6794 - val_loss: 0.5795 - val_acc: 0.6998\n",
      "Epoch 3/10\n",
      "22451/22451 [==============================] - 28s 1ms/step - loss: 0.5517 - acc: 0.7188 - val_loss: 0.5279 - val_acc: 0.7315\n",
      "Epoch 4/10\n",
      "22451/22451 [==============================] - 28s 1ms/step - loss: 0.5110 - acc: 0.7481 - val_loss: 0.5155 - val_acc: 0.7443\n",
      "Epoch 5/10\n",
      "22451/22451 [==============================] - 28s 1ms/step - loss: 0.4707 - acc: 0.7744 - val_loss: 0.4946 - val_acc: 0.7547\n",
      "Epoch 6/10\n",
      "22451/22451 [==============================] - 28s 1ms/step - loss: 0.4343 - acc: 0.7964 - val_loss: 0.5078 - val_acc: 0.7515\n",
      "Epoch 7/10\n",
      "22451/22451 [==============================] - 28s 1ms/step - loss: 0.3949 - acc: 0.8204 - val_loss: 0.5192 - val_acc: 0.7627\n",
      "Epoch 8/10\n",
      "22451/22451 [==============================] - 28s 1ms/step - loss: 0.3499 - acc: 0.8448 - val_loss: 0.5235 - val_acc: 0.7607\n",
      "Epoch 9/10\n",
      "22451/22451 [==============================] - 28s 1ms/step - loss: 0.3018 - acc: 0.8656 - val_loss: 0.5637 - val_acc: 0.7627\n",
      "Epoch 10/10\n",
      "22451/22451 [==============================] - 28s 1ms/step - loss: 0.2508 - acc: 0.8951 - val_loss: 0.6514 - val_acc: 0.7515\n",
      "Train on 22451 samples, validate on 2495 samples\n",
      "Epoch 1/10\n",
      "22451/22451 [==============================] - 54s 2ms/step - loss: 0.6605 - acc: 0.5868 - val_loss: 0.5976 - val_acc: 0.6818\n",
      "Epoch 2/10\n",
      "22451/22451 [==============================] - 54s 2ms/step - loss: 0.5824 - acc: 0.6934 - val_loss: 0.5401 - val_acc: 0.7315\n",
      "Epoch 3/10\n",
      "22451/22451 [==============================] - 54s 2ms/step - loss: 0.5127 - acc: 0.7493 - val_loss: 0.4985 - val_acc: 0.7531\n",
      "Epoch 4/10\n",
      "22451/22451 [==============================] - 54s 2ms/step - loss: 0.4473 - acc: 0.7925 - val_loss: 0.4750 - val_acc: 0.7800\n",
      "Epoch 5/10\n",
      "22451/22451 [==============================] - 54s 2ms/step - loss: 0.3716 - acc: 0.8340 - val_loss: 0.4927 - val_acc: 0.7643\n",
      "Epoch 6/10\n",
      "22451/22451 [==============================] - 54s 2ms/step - loss: 0.2802 - acc: 0.8819 - val_loss: 0.5361 - val_acc: 0.7776\n",
      "Epoch 7/10\n",
      "22451/22451 [==============================] - 54s 2ms/step - loss: 0.1889 - acc: 0.9241 - val_loss: 0.6877 - val_acc: 0.7571\n",
      "Epoch 8/10\n",
      "22451/22451 [==============================] - 54s 2ms/step - loss: 0.1084 - acc: 0.9593 - val_loss: 1.0290 - val_acc: 0.7591\n",
      "Epoch 9/10\n",
      "22451/22451 [==============================] - 54s 2ms/step - loss: 0.0765 - acc: 0.9713 - val_loss: 1.1858 - val_acc: 0.7655\n",
      "Epoch 10/10\n",
      "22451/22451 [==============================] - 54s 2ms/step - loss: 0.0592 - acc: 0.9800 - val_loss: 1.2120 - val_acc: 0.7663\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import backend as K\n",
    "\n",
    "# NOTE: To shrink the VRAM fraction add this to ConfigProto\n",
    "# gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.333)\n",
    "# K.tf.ConfigProto(gpu_options=gpu_options)\n",
    "\n",
    "cfg = K.tf.ConfigProto(device_count = {'CPU' : 1, 'GPU' : 1})\n",
    "cfg.gpu_options.allow_growth = True\n",
    "K.set_session(K.tf.Session(config=cfg))\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D\n",
    "from keras.utils import normalize\n",
    "from keras.callbacks import TensorBoard\n",
    "\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "X = pickle.load(open(\"data/pickled/X.pickle\", \"rb\"))\n",
    "y = pickle.load(open(\"data/pickled/y.pickle\", \"rb\"))\n",
    "\n",
    "X = keras.utils.normalize(X, axis=1)\n",
    "\n",
    "for dense_layer in dense_layers:\n",
    "    for layer_size in layer_sizes:\n",
    "        for conv_layer in conv_layers:\n",
    "            K.clear_session()\n",
    "            NAME = \"{}-conv-{}-nodes{}-dense-{}\".format(conv_layer, layer_size, dense_layer, int(time.time()))\n",
    "            tensorboard = TensorBoard(log_dir='logs_r2/{}'.format(NAME))\n",
    "            \n",
    "            model = Sequential()\n",
    "\n",
    "            # the 128 can be anything\n",
    "            # 3,3 is the window of the convolution (3 pixels X 3 pixels)\n",
    "            # X.shape[1:] is 128, 128, 1 based ont he fact that I transformed the images to 128X128 pixes\n",
    "            model.add(Conv2D(layer_size, (3,3), input_shape = X.shape[1:]))\n",
    "            model.add(Activation(\"relu\"))\n",
    "            model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "            \n",
    "            for l in range(conv_layer-1):\n",
    "                model.add(Conv2D(layer_size, (3,3)))\n",
    "                model.add(Activation(\"relu\"))\n",
    "                model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "            \n",
    "            model.add(Flatten())\n",
    "            for l in range(dense_layer):\n",
    "                model.add(Dense(layer_size))\n",
    "                model.add(Activation(\"relu\"))\n",
    "\n",
    "            # Output Layer\n",
    "            model.add(Dense(1))\n",
    "            model.add(Activation('sigmoid'))\n",
    "\n",
    "            model.compile(loss='binary_crossentropy',\n",
    "                         optimizer='adam',\n",
    "                         metrics=['accuracy'])\n",
    "\n",
    "            model.fit(X, y, batch_size=32, epochs=10, validation_split=0.1, callbacks=[tensorboard])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
